{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42947f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laral\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import ray\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import hytools as ht\n",
    "from hytools.io.envi import *\n",
    "from hytools.topo import calc_topo_coeffs\n",
    "from hytools.brdf import calc_brdf_coeffs\n",
    "from hytools.masks import mask_create\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0a2b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 CPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 16:18:11,717\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating topographic coefficients.\n",
      "TOPO Time: 0.00034080000000002997 sec.\n",
      "Scene average solar zenith angle : nan degrees\n",
      "Calculating BRDF coefficients\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 172>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m masks\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m correction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     38\u001b[0m     time_brdf_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;66;03m#.process_time_ns()\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mcalc_brdf_coeffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     time_brdf_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;66;03m#.process_time_ns()\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBRDF Time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sec.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time_brdf_end \u001b[38;5;241m-\u001b[39m time_brdf_start))\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\hytools\\hytools\\brdf\\brdf.py:89\u001b[0m, in \u001b[0;36mcalc_brdf_coeffs\u001b[1;34m(actors, config_dict)\u001b[0m\n\u001b[0;32m     87\u001b[0m     universal_brdf(actors,config_dict)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m brdf_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflex\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mflex_brdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m brdf_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal/class BRDF correction....under development\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\hytools\\hytools\\brdf\\flex.py:39\u001b[0m, in \u001b[0;36mflex_brdf\u001b[1;34m(actors, config_dict)\u001b[0m\n\u001b[0;32m     37\u001b[0m brdf_dict\u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrdf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m brdf_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrouped\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 39\u001b[0m     actors \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_flex_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbrdf_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     _ \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget([a\u001b[38;5;241m.\u001b[39mdo\u001b[38;5;241m.\u001b[39mremote(calc_flex_single,brdf_dict) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m actors])\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\hytools\\hytools\\brdf\\flex.py:162\u001b[0m, in \u001b[0;36mcalc_flex_group\u001b[1;34m(actors, brdf_dict)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Aggregate NDVI values from images\u001b[39;00m\n\u001b[0;32m    161\u001b[0m ndvi \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget([a\u001b[38;5;241m.\u001b[39mndi\u001b[38;5;241m.\u001b[39mremote(mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_data\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m actors])\n\u001b[1;32m--> 162\u001b[0m ndvi \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mndvi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Determine bin dimensions\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m  brdf_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbin_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    time_start = time.perf_counter() #process_time_ns()\n",
    "\n",
    "    config_file = sys.argv[1]\n",
    "\n",
    "    with open(\"E:/wenqu/aviris/new_aviris_update/site2a/topo_brdf.json\", 'r') as outfile:\n",
    "        config_dict = json.load(outfile)\n",
    "\n",
    "    images= config_dict[\"input_files\"]\n",
    "\n",
    "    if ray.is_initialized():\n",
    "        ray.shutdown()\n",
    "    print(\"Using %s CPUs.\" % config_dict['num_cpus'])\n",
    "    ray.init(num_cpus = config_dict['num_cpus'])\n",
    "\n",
    "    HyTools = ray.remote(ht.HyTools)\n",
    "    actors = [HyTools.remote() for image in images]\n",
    "\n",
    "    if config_dict['file_type'] == 'envi':\n",
    "        anc_files = config_dict[\"anc_files\"]\n",
    "        _ = ray.get([a.read_file.remote(image,config_dict['file_type'],\n",
    "                                        anc_files[image]) for a,image in zip(actors,images)])\n",
    "    elif config_dict['file_type'] == 'neon':\n",
    "        _ = ray.get([a.read_file.remote(image,config_dict['file_type']) for a,image in zip(actors,images)])\n",
    "\n",
    "    #Here is where the outlier detection should probably happen.\n",
    "\n",
    "    _ = ray.get([a.create_bad_bands.remote(config_dict['bad_bands']) for a in actors])\n",
    "\n",
    "    for correction in config_dict[\"corrections\"]:\n",
    "        if correction =='topo':\n",
    "            time_topo_start = time.perf_counter() #process_time_ns()\n",
    "            calc_topo_coeffs(actors,config_dict['topo'])\n",
    "            time_topo_end = time.perf_counter() #process_time_ns()\n",
    "            print(\"TOPO Time: {} sec.\".format(time_topo_end - time_topo_start))\n",
    "        elif correction == 'brdf':\n",
    "            time_brdf_start = time.perf_counter() #.process_time_ns()\n",
    "            calc_brdf_coeffs(actors,config_dict)\n",
    "            time_brdf_end = time.perf_counter() #.process_time_ns()\n",
    "            print(\"BRDF Time: {} sec.\".format(time_brdf_end - time_brdf_start))\n",
    "        elif correction == 'unsmooth':\n",
    "            load_unsmooth(actors)\n",
    "\n",
    "    if config_dict['export']['coeffs'] and len(config_dict[\"corrections\"]) > 0:\n",
    "        print(\"Exporting correction coefficients.\")\n",
    "        _ = ray.get([a.do.remote(export_coeffs,config_dict['export']) for a in actors])\n",
    "\n",
    "    #print('image_correct.py Ln59:',config_dict[\"corrections\"])\n",
    "    time_export_start = time.perf_counter() #process_time_ns()\n",
    "    if config_dict['export']['image']:\n",
    "        print(\"Exporting corrected images.\")\n",
    "        _ = ray.get([a.do.remote(apply_corrections,config_dict) for a in actors])\n",
    "    time_export_end = time.perf_counter() #process_time_ns()\n",
    "    print(\"{} Export Time: {} sec.\".format(images[0],time_export_end - time_export_start))\n",
    "\n",
    "\n",
    "    ray.shutdown()\n",
    "\n",
    "    time_end = time.perf_counter() #process_time_ns()\n",
    "    print(\"Total Time: {} sec.\".format(time_end - time_start))\n",
    "\n",
    "def export_coeffs(hy_obj,export_dict):\n",
    "    '''Export correction coefficients to file.\n",
    "    '''\n",
    "    for correction in hy_obj.corrections:\n",
    "        if correction=='unsmooth':\n",
    "            continue\n",
    "\n",
    "        coeff_file = export_dict['output_dir']\n",
    "        coeff_file += os.path.splitext(os.path.basename(hy_obj.file_name))[0]\n",
    "        coeff_file += \"_%s_coeffs_%s.json\" % (correction,export_dict[\"suffix\"])\n",
    "\n",
    "        with open(coeff_file, 'w') as outfile:\n",
    "            if correction == 'topo':\n",
    "                corr_dict = hy_obj.topo\n",
    "            else:\n",
    "                corr_dict = hy_obj.brdf\n",
    "            json.dump(corr_dict,outfile)\n",
    "\n",
    "def apply_corrections(hy_obj,config_dict):\n",
    "    '''Apply correction to image and export\n",
    "        to file.\n",
    "    '''\n",
    "\n",
    "    header_dict = hy_obj.get_header()\n",
    "    header_dict['data ignore value'] = hy_obj.no_data\n",
    "    header_dict['data type'] = 4\n",
    "\n",
    "    output_name = config_dict['export']['output_dir']\n",
    "    output_name += os.path.splitext(os.path.basename(hy_obj.file_name))[0]\n",
    "    output_name +=  \"_%s\" % config_dict['export'][\"suffix\"]\n",
    "\n",
    "    #Export all wavelengths\n",
    "    if len(config_dict['export']['subset_waves']) == 0:\n",
    "\n",
    "        if config_dict[\"resample\"] == True:\n",
    "            hy_obj.resampler = config_dict['resampler']\n",
    "            waves= hy_obj.resampler['out_waves']\n",
    "        else:\n",
    "            waves = hy_obj.wavelengths\n",
    "\n",
    "        header_dict['bands'] = len(waves)\n",
    "        header_dict['wavelength'] = waves\n",
    "        header_dict['fwhm'] = hy_obj.fwhm\n",
    "\n",
    "        writer = WriteENVI(output_name,header_dict)\n",
    "        iterator = hy_obj.iterate(by = 'line', corrections = hy_obj.corrections,\n",
    "                                  resample = config_dict['resample'])\n",
    "        while not iterator.complete:\n",
    "            line = iterator.read_next()\n",
    "            writer.write_line(line,iterator.current_line)\n",
    "        writer.close()\n",
    "\n",
    "    #Export subset of wavelengths\n",
    "    else:\n",
    "        waves = config_dict['export']['subset_waves']\n",
    "        bands = [hy_obj.wave_to_band(x) for x in waves]\n",
    "        waves = [round(hy_obj.wavelengths[x],2) for x in bands]\n",
    "        header_dict['bands'] = len(bands)\n",
    "        header_dict['wavelength'] = waves\n",
    "        header_dict['fwhm'] = [hy_obj.fwhm[x] for x in bands]\n",
    "\n",
    "        writer = WriteENVI(output_name,header_dict)\n",
    "        for b,band_num in enumerate(bands):\n",
    "            #print('image_correct.py Ln 123',hy_obj.corrections)\n",
    "            band = hy_obj.get_band(band_num,\n",
    "                                   corrections = hy_obj.corrections)\n",
    "            writer.write_band(band, b)\n",
    "        writer.close()\n",
    "\n",
    "    #Export masks\n",
    "    # does not work for precomputed json coeffs\n",
    "    if (config_dict['export']['masks']) and (len(config_dict[\"corrections\"]) > 0):\n",
    "        masks = []\n",
    "        mask_names = []\n",
    "\n",
    "        for correction in config_dict[\"corrections\"]:\n",
    "            if correction=='unsmooth':\n",
    "                continue\n",
    "            #for mask_type in config_dict[correction]['calc_mask']:\n",
    "            for mask_type in config_dict[correction]['apply_mask']:\n",
    "                mask_names.append(correction + '_' + mask_type[0])\n",
    "                masks.append(mask_create(hy_obj, [mask_type]))\n",
    "\n",
    "        header_dict['data type'] = 1\n",
    "        header_dict['bands'] = len(masks)\n",
    "        header_dict['band names'] = mask_names\n",
    "        header_dict['samples'] = hy_obj.columns\n",
    "        header_dict['lines'] = hy_obj.lines\n",
    "        header_dict['wavelength'] = []\n",
    "        header_dict['fwhm'] = []\n",
    "        header_dict['wavelength units'] = ''\n",
    "        header_dict['data ignore value'] = 255\n",
    "\n",
    "\n",
    "        output_name = config_dict['export']['output_dir']\n",
    "        output_name += os.path.splitext(os.path.basename(hy_obj.file_name))[0]\n",
    "        output_name +=  \"_%s_mask\" % config_dict['export'][\"suffix\"]\n",
    "\n",
    "        writer = WriteENVI(output_name,header_dict)\n",
    "\n",
    "        for band_num,mask in enumerate(masks):\n",
    "            mask =mask.astype(int)\n",
    "            mask[~hy_obj.mask['no_data']] = 255\n",
    "            writer.write_band(mask,band_num)\n",
    "\n",
    "        del masks\n",
    "\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a3d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc7645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376eb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenqu_gpu",
   "language": "python",
   "name": "wenqu_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
