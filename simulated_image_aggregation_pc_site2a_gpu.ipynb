{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339a3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from arsf_envi_reader import envi_header\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from osgeo import gdal,ogr,osr\n",
    "from scipy.optimize import curve_fit\n",
    "# from tqdm import tqdm\n",
    "# import multiprocess as mp\n",
    "from scipy import ndimage\n",
    "from numpy import trapz\n",
    "# import cupy as cp\n",
    "from scipy import ndimage\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c07293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb493f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp39-cp39-win_amd64.whl (222.0 MB)\n",
      "     ------------------------------------- 222.0/222.0 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.10.0\n",
      "  Downloading torchvision-0.10.0-cp39-cp39-win_amd64.whl (920 kB)\n",
      "     ------------------------------------- 920.7/920.7 kB 29.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torch==1.9.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torchvision==0.10.0) (1.23.4)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torchvision==0.10.0) (9.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.0\n",
      "    Uninstalling torch-1.13.0:\n",
      "      Successfully uninstalled torch-1.13.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.0\n",
      "    Uninstalling torchvision-0.14.0:\n",
      "      Successfully uninstalled torchvision-0.14.0\n",
      "Successfully installed torch-1.9.0 torchvision-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.13.0 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch==1.9.0 torchvision==0.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c126074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (0.13.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 19.4 MB/s eta 0:00:00\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     ------------------------------------- 172.4/172.4 MB 16.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)Note: you may need to restart the kernel to use updated packages.\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torch==2.0.1->torchaudio) (3.9.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 26.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from torch==2.0.1->torchaudio) (4.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\laral\\anaconda3\\envs\\wenqu_gpu\\lib\\site-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------- 536.2/536.2 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, torch, torchaudio\n",
      "\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.0\n",
      "    Uninstalling torchaudio-0.13.0:\n",
      "      Successfully uninstalled torchaudio-0.13.0\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 torchaudio-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.0 requires torch==1.9.0, but you have torch 2.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ddba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46cebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee43f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7f42bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 5218, 5519)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_res_img = gdal.Open(r'D:\\wenqu\\mosaic\\site2a\\site2a_simulation_mosaic')\n",
    "high_res_radiance = gdal.Open(r'D:\\wenqu\\mosaic\\site2a\\site2a_simulation_mosaic').ReadAsArray() \n",
    "# high_res_radiance_torch = torch.from_numpy(high_res_radiance).float().to(device)\n",
    "high_res_radiance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e44683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_res_radiance_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e6ff9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'nanstd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Apply the generic filter using unfold and conv2d\u001b[39;00m\n\u001b[0;32m     13\u001b[0m unfolded \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39munfold(padded_tensor, kernel_size\u001b[38;5;241m=\u001b[39mfilter_size)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m---> 14\u001b[0m std_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanstd\u001b[49m(unfolded, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Remove the padding from the std values\u001b[39;00m\n\u001b[0;32m     17\u001b[0m b42_std \u001b[38;5;241m=\u001b[39m std_values\u001b[38;5;241m.\u001b[39mview(b42\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], b42\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'nanstd'"
     ]
    }
   ],
   "source": [
    "# Convert the band to a tensor on the GPU\n",
    "b119 = high_res_radiance[118, :, :]\n",
    "b42_tensor = torch.from_numpy(b119).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "\n",
    "# Define the size of the filter window\n",
    "filter_size = 11\n",
    "\n",
    "# Pad the tensor to handle border cases\n",
    "pad_size = (filter_size - 1) // 2\n",
    "padded_tensor = F.pad(b42_tensor, (pad_size, pad_size, pad_size, pad_size), value=float('nan'))\n",
    "\n",
    "# Apply the generic filter using unfold and conv2d\n",
    "unfolded = F.unfold(padded_tensor, kernel_size=filter_size).squeeze()\n",
    "std_values = torch.nanstd(unfolded, dim=1)\n",
    "\n",
    "# Remove the padding from the std values\n",
    "b42_std = std_values.view(b42.shape[0], b42.shape[1]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812e7068",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh_res_radiance_torch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m121\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\pyplot.py:2650\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2646\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2647\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2648\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2649\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2650\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2651\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2652\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2653\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2654\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2655\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2656\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2657\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2658\u001b[0m     sci(__ret)\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\__init__.py:1414\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1416\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1417\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1418\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5487\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5481\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[0;32m   5482\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5483\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5484\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5485\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5487\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5488\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5490\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\image.py:702\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    701\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be converted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:701\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_masked_invalid\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 701\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\wenqu_gpu\\lib\\site-packages\\torch\\_tensor.py:955\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.imshow(high_res_radiance_torch[121,:,:], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b119 = high_res_radiance[118, :, :]\n",
    "b119_std = ndimage.generic_filter(b119, np.nanstd, size=(11,11), mode='constant', cval=np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52f6cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9106, 8882)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b119_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8aa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b107 = high_res_radiance[106, :, :]\n",
    "b107_std = ndimage.generic_filter(b107, np.nanstd, size=11, mode='constant', cval=np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6062253",
   "metadata": {},
   "outputs": [],
   "source": [
    "b117 = high_res_radiance[116, :, :]\n",
    "b117_std = ndimage.generic_filter(b117, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3072a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "b108 = high_res_radiance[107, :, :]\n",
    "b108_std = ndimage.generic_filter(b108, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c6bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "b17 = high_res_radiance[16, :, :]\n",
    "b17_std = ndimage.generic_filter(b17, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96671667",
   "metadata": {},
   "outputs": [],
   "source": [
    "b122 = high_res_radiance[121, :, :]\n",
    "b122_mean = ndimage.generic_filter(b122, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c690c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b97 = high_res_radiance[96, :, :]\n",
    "b97_std = ndimage.generic_filter(b97, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e8e9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b9 = high_res_radiance[8, :, :]\n",
    "b9_std = ndimage.generic_filter(b9, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6530106",
   "metadata": {},
   "outputs": [],
   "source": [
    "b46 = high_res_radiance[45, :, :]\n",
    "b46_std = ndimage.generic_filter(b46, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b110 = high_res_radiance[109, :, :]\n",
    "b110_mean = ndimage.generic_filter(b110, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "b15 = high_res_radiance[14, :, :]\n",
    "b15_std = ndimage.generic_filter(b15, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b42 = high_res_radiance[41, :, :]\n",
    "b42_std = ndimage.generic_filter(b42, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e293cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "b37 = high_res_radiance[36, :, :]\n",
    "b37_std = ndimage.generic_filter(b37, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b113 = high_res_radiance[112, :, :]\n",
    "b113_std = ndimage.generic_filter(b113, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b111 = high_res_radiance[110, :, :]\n",
    "b111_std = ndimage.generic_filter(b111, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "b86 = high_res_radiance[85, :, :]\n",
    "b86_std = ndimage.generic_filter(b86, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "b6 = high_res_radiance[5, :, :]\n",
    "b6_mean = ndimage.generic_filter(b6, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "b10 = high_res_radiance[9, :, :]\n",
    "b10_mean = ndimage.generic_filter(b10, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b20 = high_res_radiance[19, :, :]\n",
    "b20_mean = ndimage.generic_filter(b20, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4021cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b114 = high_res_radiance[113, :, :]\n",
    "b114_mean = ndimage.generic_filter(b114, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "b113 = high_res_radiance[112, :, :]\n",
    "b113_mean = ndimage.generic_filter(b113, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a547d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "b48 = high_res_radiance[47, :, :]\n",
    "b48_mean = ndimage.generic_filter(b48, np.nanmean, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ddc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "b6 = high_res_radiance[5, :, :]\n",
    "b6_std = ndimage.generic_filter(b6, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b91 = high_res_radiance[90, :, :]\n",
    "b91_std = ndimage.generic_filter(b91, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de068f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "b39 = high_res_radiance[38, :, :]\n",
    "b39_std = ndimage.generic_filter(b39, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b23 = high_res_radiance[22, :, :]\n",
    "b23_std = ndimage.generic_filter(b23, np.nanstd, size=11, mode='constant', cval=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "site6_logpc_traitmap = (-0.11896496*b119_std,  \n",
    "                      +0.10664171*b107_std, \n",
    "                      -0.086348*b117_std,  \n",
    "                      +0.07304101*b108_std, \n",
    "                      -0.07094559*b17_std,\n",
    "                      +0.06625993*b122_mean, \n",
    "                      -0.06341419*b97_std, \n",
    "                      -0.06157008*b9_std, \n",
    "                      -0.06129507*b46_std, \n",
    "                      -0.05904957*b110_mean,\n",
    "                      +0.05886772*b15_std, \n",
    "                      -0.05829401*b42_std,  \n",
    "                      +0.05618142*b37_std,  \n",
    "                      +0.05422837*b113_std,  \n",
    "                      +0.0535395*b111_std,\n",
    "                      +0.05329481*b86_std,  \n",
    "                      +0.05109891*b6_mean, \n",
    "                      -0.04969719*b10_mean,  \n",
    "                      +0.04969354*b20_mean,  \n",
    "                      +0.04917988*b114_mean,\n",
    "                      +0.04828722*b113_mean, \n",
    "                      -0.04732767*b48_mean,  \n",
    "                      +0.04654021*b6_std, \n",
    "                      -0.04487358*b91_std,  \n",
    "                      +0.04483862*b39_std,\n",
    "                      +0.04398*b23_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26027de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pj = high_res_img.GetProjection()  ## projection \n",
    "gt = high_res_img.GetGeoTransform()  ## geotransform\n",
    "col = high_res_img.GetRasterBand(1).XSize\n",
    "row = high_res_img.GetRasterBand(1).YSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName('GTiff')  ## driver for output file type; \"GTiff\" for geotiff, \"RST\" for rst\n",
    "bands =1\n",
    "outName = \"site6_logpc_trait_map.tiff\"\n",
    "outPath ='D:/wenqu/image_aggregation'\n",
    "out_ds = driver.Create(os.path.join(outPath, outName),col,row,bands,gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e90adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ds.GetRasterBand(1).WriteArray(site6_logpc_traitmap)\n",
    "out_ds.SetProjection(pj)\n",
    "out_ds.SetGeoTransform(gt)\n",
    "del out_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f79cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6a629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenqu_gpu",
   "language": "python",
   "name": "wenqu_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
